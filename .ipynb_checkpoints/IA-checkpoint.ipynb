{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The duration of 0_0000.wav in seconds: 10.0\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "# sr should be set to your recording sample rate (16k)\n",
    "x,freq = librosa.load(\"C:/Users/matte/Desktop/IA/HIP_HOP_MUSIC/0_0000.wav\",sr=16000)\n",
    "# The load function will return a time series value (x) and\n",
    "# the input sample rate (freq) which is 16000\n",
    "print(\"The duration of 0_0000.wav in seconds:\",len(x)/freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The duration of 0_0000.wav in seconds: 10.0\n"
     ]
    }
   ],
   "source": [
    "x=x[:160000]\n",
    "print(\"The duration of 0_0000.wav in seconds:\",len(x)/freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 313)\n"
     ]
    }
   ],
   "source": [
    "# This function will return n_mfcc number of MFCC per\n",
    "# a window of time in audio time series\n",
    "x_mfcc=librosa.feature.mfcc(x,sr=freq , n_mfcc=40)\n",
    "print(x_mfcc.shape)\n",
    "\n",
    "# x_mfcc is an array with 40 values for a window of time\n",
    "# The len(x_mfcc) is a proportion of wav file duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matte\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/matte/Desktop/IA/Data/HIP_HOP_MUSIC/0_0263.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'r+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid file: {0!r}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m         _error_check(_snd.sf_error(file_ptr),\n\u001b[0m\u001b[0;32m   1184\u001b[0m                      \"Error opening {0!r}: \".format(self.name))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[1;34m(err, prefix)\u001b[0m\n\u001b[0;32m   1356\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1357\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error opening 'C:/Users/matte/Desktop/IA/Data/HIP_HOP_MUSIC/0_0263.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3567d9b52e14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0mfile_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[1;31m#add extracted feature to dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mx_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-3567d9b52e14>\u001b[0m in \u001b[0;36mfeature_extractor\u001b[1;34m(audio_file_dir)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_file_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#load the audio files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_file_dir\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;31m#extract 20 MFCCs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mmfcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreq\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mn_mfcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPurePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\audioread\\__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\audioread\\rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \"\"\"\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/matte/Desktop/IA/Data/HIP_HOP_MUSIC/0_0263.wav'"
     ]
    }
   ],
   "source": [
    "#NE PAS EXECUTER CE CODE, MAIS CELUI D'APRES (fin vous pouvez mais ça sert à rien)\n",
    "#\n",
    "#\n",
    "#On garde ce code car c'est une autre façon de faire\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "def feature_extractor(audio_file_dir):\n",
    "    #load the audio files\n",
    "    x,freq = librosa.load(audio_file_dir ,sr=16000)\n",
    "    #extract 20 MFCCs\n",
    "    mfcc=librosa.feature.mfcc(x,sr=freq ,n_mfcc=20)\n",
    "    # calculate the mean and variance of each MFFC\n",
    "    mean_mfccs=np.mean(mfcc ,axis=1)\n",
    "    var_mfccs=np.var(mfcc ,axis=1)\n",
    "    #return mean and variance as the audio file feature\n",
    "    return list(mean_mfccs)+list(var_mfccs)\n",
    "\n",
    "#set data_dir to the directory of your data files\n",
    "data_dir= \"C:/Users/matte/Desktop/IA/Data/HIP_HOP_MUSIC/\"\n",
    "\n",
    "# Read file info file to get the list of audio files and their labels\n",
    "file_list=[]\n",
    "label_list=[]\n",
    "\n",
    "\n",
    "with open(data_dir+\"info.txt\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        # The first column contains the file name\n",
    "        file_list.append(row[0])\n",
    "        # The last column contains the lable (language)\n",
    "        label_list.append(row[0][0])\n",
    "\n",
    "#set data_dir to the directory of your data files\n",
    "data_dir= \"C:/Users/matte/Desktop/IA/Data/CLASSIC_MUSIC/\"\n",
    "\n",
    "with open(data_dir+\"info.txt\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        # The first column contains the file name\n",
    "        file_list.append(row[0])\n",
    "        # The last column contains the lable (language)\n",
    "        label_list.append(row[0][0])\n",
    "\n",
    "        \n",
    "        \n",
    "data_dir= \"C:/Users/matte/Desktop/IA/Data/HIP_HOP_MUSIC/\"\n",
    "# create a dictionary for labels\n",
    "lang_dic={'0':0,'1':1,'2':2,'3':3,}\n",
    "# create a list of extracted feature (MFCC) for files\n",
    "x_data=[]\n",
    "for audio_file in file_list:\n",
    "    \n",
    "    if audio_file[0]=='1':\n",
    "        data_dir= \"C:/Users/matte/Desktop/IA/Data/CLASSIC_MUSIC/\"\n",
    "        \n",
    "    \n",
    "    file_feature = feature_extractor(data_dir+audio_file)\n",
    "    #add extracted feature to dataset\n",
    "    x_data.append(file_feature)\n",
    "    \n",
    "# create a list of labels for files\n",
    "y_data=[]\n",
    "for lang_label in label_list:\n",
    "    #convert the label to a value in {0,1,2,3} as the class label\n",
    "    print(lang_dic[lang_label])\n",
    "    y_data.append(lang_dic[lang_label])\n",
    "    \n",
    "    \n",
    "# shuffle two lists\n",
    "temp_list = list(zip(x_data , y_data))\n",
    "random.shuffle(temp_list)\n",
    "x_data , y_data = zip(*temp_list)\n",
    "# create Random Forest model from sklearn to classify languages of audio files\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "x_test = x_data[:len(x_data) // 8]\n",
    "y_test = y_data[:len(y_data) // 8]\n",
    "\n",
    "x_train = x_data[len(x_data) // 8:]\n",
    "y_train = y_data[len(y_data) // 8:]\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# the resulted accuracy is on a small set which is same for train and test\n",
    "print(\"Accuracy\",clf.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(audio_file_dir):\n",
    "#load the audio files\n",
    "    x,freq = librosa.load(audio_file_dir ,sr=16000)\n",
    "# trim the first 5 seconds (Sequence Truncation )\n",
    "    x_10sec=x[:160000]\n",
    "# extract 20 MFCCs\n",
    "    mfccs_10sec=librosa.feature.mfcc(x_10sec ,sr=freq ,n_mfcc=20)\n",
    "# return mfcc of the first 5 sec as the audio file feature\n",
    "    return mfccs_10sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_0000.wav\n",
      "0_0001.wav\n",
      "0_0002.wav\n",
      "0_0003.wav\n",
      "0_0004.wav\n",
      "0_0005.wav\n",
      "0_0006.wav\n",
      "0_0007.wav\n",
      "0_0008.wav\n",
      "0_0009.wav\n",
      "0_0010.wav\n",
      "0_0011.wav\n",
      "0_0012.wav\n",
      "0_0013.wav\n",
      "0_0014.wav\n",
      "0_0015.wav\n",
      "0_0016.wav\n",
      "0_0017.wav\n",
      "0_0018.wav\n",
      "0_0019.wav\n",
      "0_0020.wav\n",
      "0_0021.wav\n",
      "0_0022.wav\n",
      "0_0023.wav\n",
      "0_0024.wav\n",
      "0_0025.wav\n",
      "0_0026.wav\n",
      "0_0027.wav\n",
      "0_0028.wav\n",
      "0_0029.wav\n",
      "0_0030.wav\n",
      "0_0031.wav\n",
      "0_0032.wav\n",
      "0_0033.wav\n",
      "0_0034.wav\n",
      "0_0035.wav\n",
      "0_0036.wav\n",
      "0_0037.wav\n",
      "0_0038.wav\n",
      "0_0039.wav\n",
      "0_0040.wav\n",
      "0_0041.wav\n",
      "0_0042.wav\n",
      "0_0043.wav\n",
      "0_0044.wav\n",
      "0_0045.wav\n",
      "0_0046.wav\n",
      "0_0047.wav\n",
      "0_0048.wav\n",
      "0_0049.wav\n",
      "0_0050.wav\n",
      "0_0051.wav\n",
      "0_0052.wav\n",
      "0_0053.wav\n",
      "0_0054.wav\n",
      "0_0055.wav\n",
      "0_0056.wav\n",
      "0_0057.wav\n",
      "0_0058.wav\n",
      "0_0059.wav\n",
      "0_0060.wav\n",
      "0_0061.wav\n",
      "0_0062.wav\n",
      "0_0063.wav\n",
      "0_0064.wav\n",
      "0_0065.wav\n",
      "0_0066.wav\n",
      "0_0067.wav\n",
      "0_0068.wav\n",
      "0_0069.wav\n",
      "0_0070.wav\n",
      "0_0071.wav\n",
      "0_0072.wav\n",
      "0_0073.wav\n",
      "0_0074.wav\n",
      "0_0075.wav\n",
      "0_0076.wav\n",
      "0_0077.wav\n",
      "0_0078.wav\n",
      "0_0079.wav\n",
      "0_0080.wav\n",
      "0_0081.wav\n",
      "0_0082.wav\n",
      "0_0083.wav\n",
      "0_0084.wav\n",
      "0_0085.wav\n",
      "0_0086.wav\n",
      "0_0087.wav\n",
      "0_0088.wav\n",
      "0_0089.wav\n",
      "0_0090.wav\n",
      "0_0091.wav\n",
      "0_0092.wav\n",
      "0_0093.wav\n",
      "0_0094.wav\n",
      "0_0095.wav\n",
      "0_0096.wav\n",
      "0_0097.wav\n",
      "0_0098.wav\n",
      "0_0099.wav\n",
      "0_0100.wav\n",
      "0_0101.wav\n",
      "0_0102.wav\n",
      "0_0103.wav\n",
      "0_0104.wav\n",
      "0_0105.wav\n",
      "0_0106.wav\n",
      "0_0107.wav\n",
      "0_0108.wav\n",
      "0_0109.wav\n",
      "0_0110.wav\n",
      "0_0111.wav\n",
      "0_0112.wav\n",
      "0_0113.wav\n",
      "0_0115.wav\n",
      "0_0116.wav\n",
      "0_0117.wav\n",
      "0_0118.wav\n",
      "0_0119.wav\n",
      "0_0120.wav\n",
      "0_0121.wav\n",
      "0_0122.wav\n",
      "0_0123.wav\n",
      "0_0124.wav\n",
      "0_0125.wav\n",
      "0_0126.wav\n",
      "0_0127.wav\n",
      "0_0128.wav\n",
      "0_0129.wav\n",
      "0_0130.wav\n",
      "0_0131.wav\n",
      "0_0132.wav\n",
      "0_0133.wav\n",
      "0_0134.wav\n",
      "0_0135.wav\n",
      "0_0139.wav\n",
      "0_0140.wav\n",
      "0_0141.wav\n",
      "0_0142.wav\n",
      "0_0143.wav\n",
      "0_0144.wav\n",
      "0_0145.wav\n",
      "0_0146.wav\n",
      "0_0147.wav\n",
      "0_0149.wav\n",
      "0_0150.wav\n",
      "0_0151.wav\n",
      "0_0152.wav\n",
      "0_0153.wav\n",
      "0_0154.wav\n",
      "0_0155.wav\n",
      "0_0156.wav\n",
      "0_0157.wav\n",
      "0_0158.wav\n",
      "0_0159.wav\n",
      "0_0160.wav\n",
      "0_0161.wav\n",
      "0_0162.wav\n",
      "0_0163.wav\n",
      "0_0164.wav\n",
      "0_0165.wav\n",
      "0_0166.wav\n",
      "0_0167.wav\n",
      "0_0168.wav\n",
      "0_0169.wav\n",
      "0_0170.wav\n",
      "0_0171.wav\n",
      "0_0172.wav\n",
      "0_0173.wav\n",
      "0_0174.wav\n",
      "0_0175.wav\n",
      "0_0176.wav\n",
      "0_0177.wav\n",
      "0_0178.wav\n",
      "0_0179.wav\n",
      "0_0180.wav\n",
      "0_0181.wav\n",
      "0_0182.wav\n",
      "0_0183.wav\n",
      "0_0184.wav\n",
      "0_0185.wav\n",
      "0_0186.wav\n",
      "0_0187.wav\n",
      "0_0188.wav\n",
      "0_0189.wav\n",
      "0_0190.wav\n",
      "0_0191.wav\n",
      "0_0192.wav\n",
      "0_0193.wav\n",
      "0_0194.wav\n",
      "0_0195.wav\n",
      "0_0196.wav\n",
      "0_0197.wav\n",
      "0_0198.wav\n",
      "0_0199.wav\n",
      "0_0200.wav\n",
      "0_0201.wav\n",
      "0_0202.wav\n",
      "0_0203.wav\n",
      "0_0204.wav\n",
      "0_0205.wav\n",
      "0_0206.wav\n",
      "0_0207.wav\n",
      "0_0208.wav\n",
      "0_0209.wav\n",
      "0_0210.wav\n",
      "0_0211.wav\n",
      "0_0212.wav\n",
      "0_0213.wav\n",
      "0_0214.wav\n",
      "0_0215.wav\n",
      "0_0216.wav\n",
      "0_0217.wav\n",
      "0_0218.wav\n",
      "0_0219.wav\n",
      "0_0220.wav\n",
      "0_0221.wav\n",
      "0_0222.wav\n",
      "0_0223.wav\n",
      "0_0224.wav\n",
      "0_0225.wav\n",
      "0_0226.wav\n",
      "0_0227.wav\n",
      "0_0228.wav\n",
      "0_0229.wav\n",
      "0_0230.wav\n",
      "0_0231.wav\n",
      "0_0232.wav\n",
      "0_0233.wav\n",
      "0_0234.wav\n",
      "0_0235.wav\n",
      "0_0236.wav\n",
      "0_0237.wav\n",
      "0_0238.wav\n",
      "0_0239.wav\n",
      "0_0240.wav\n",
      "0_0241.wav\n",
      "0_0242.wav\n",
      "0_0243.wav\n",
      "0_0244.wav\n",
      "0_0245.wav\n",
      "0_0246.wav\n",
      "0_0247.wav\n",
      "0_0248.wav\n",
      "0_0249.wav\n",
      "0_0250.wav\n",
      "0_0251.wav\n",
      "0_0252.wav\n",
      "0_0253.wav\n",
      "0_0254.wav\n",
      "0_0255.wav\n",
      "0_0256.wav\n",
      "0_0257.wav\n",
      "0_0258.wav\n",
      "0_0259.wav\n",
      "0_0260.wav\n",
      "0_0261.wav\n",
      "0_0262.wav\n",
      "0_0263.wav\n",
      "0_0264.wav\n",
      "0_0265.wav\n",
      "0_0266.wav\n",
      "0_0267.wav\n",
      "0_0268.wav\n",
      "0_0269.wav\n",
      "0_0270.wav\n",
      "0_0271.wav\n",
      "0_0272.wav\n",
      "0_0273.wav\n",
      "0_0274.wav\n",
      "0_0275.wav\n",
      "0_0276.wav\n",
      "0_0277.wav\n",
      "0_0278.wav\n",
      "1_0000.wav\n",
      "1_0001.wav\n",
      "1_0002.wav\n",
      "1_0003.wav\n",
      "1_0004.wav\n",
      "1_0005.wav\n",
      "1_0006.wav\n",
      "1_0007.wav\n",
      "1_0008.wav\n",
      "1_0009.wav\n",
      "1_0010.wav\n",
      "1_0011.wav\n",
      "1_0012.wav\n",
      "1_0013.wav\n",
      "1_0014.wav\n",
      "1_0015.wav\n",
      "1_0016.wav\n",
      "1_0017.wav\n",
      "1_0018.wav\n",
      "1_0019.wav\n",
      "1_0020.wav\n",
      "1_0021.wav\n",
      "1_0023.wav\n",
      "1_0024.wav\n",
      "1_0025.wav\n",
      "1_0026.wav\n",
      "1_0027.wav\n",
      "1_0028.wav\n",
      "1_0029.wav\n",
      "1_0030.wav\n",
      "1_0031.wav\n",
      "1_0032.wav\n",
      "1_0033.wav\n",
      "1_0034.wav\n",
      "1_0035.wav\n",
      "1_0036.wav\n",
      "1_0037.wav\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset , DataLoader\n",
    "import torch\n",
    "data_dir= \"C:/Users/matte/Desktop/IA/Data/HIP_HOP_MUSIC/\"\n",
    "\n",
    "# Read file info file to get the list of audio files and their labels\n",
    "file_list=[]\n",
    "label_list=[]\n",
    "\n",
    "with open(data_dir+\"info.txt\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        # The first column contains the file name\n",
    "        file_list.append(row[0])\n",
    "        # The last column contains the lable (language)\n",
    "        label_list.append(row[0][0])\n",
    "\n",
    "#set data_dir to the directory of your data files\n",
    "data_dir= \"C:/Users/matte/Desktop/IA/Data/CLASSIC_MUSIC/\"\n",
    "\n",
    "with open(data_dir+\"info.txt\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        # The first column contains the file name\n",
    "        file_list.append(row[0])\n",
    "        # The last column contains the lable (language)\n",
    "        label_list.append(row[0][0])\n",
    "\n",
    "        \n",
    "        \n",
    "data_dir= \"C:/Users/matte/Desktop/IA/Data/HIP_HOP_MUSIC/\"\n",
    "# create a dictionary for labels\n",
    "lang_dic={'0':0,'1':1,'2':2,'3':3,}\n",
    "# create a list of extracted feature (MFCC) for files\n",
    "x_data=[]\n",
    "for audio_file in file_list:\n",
    "    if audio_file[0]=='1':\n",
    "        data_dir= \"C:/Users/matte/Desktop/IA/Data/CLASSIC_MUSIC/\"\n",
    "        \n",
    "    print(audio_file)\n",
    "    file_feature = feature_extractor(data_dir+audio_file)\n",
    "    #add extracted feature to dataset\n",
    "    x_data.append(file_feature)\n",
    "    \n",
    "# create a list of labels for files\n",
    "y_data=[]\n",
    "for lang_label in label_list:\n",
    "    #convert the label to a value in {0,1,2,3} as the class label\n",
    "    #print(lang_dic[lang_label])\n",
    "    y_data.append(lang_dic[lang_label])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 313 at dim 2 (got 147)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-004771523971>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# transform to torch tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtensor_x_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mtensor_y_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# create your datset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 313 at dim 2 (got 147)"
     ]
    }
   ],
   "source": [
    "\n",
    "# shuffle two lists\n",
    "temp_list = list(zip(x_data , y_data))\n",
    "random.shuffle(temp_list)\n",
    "x_data , y_data = zip(*temp_list)\n",
    "\n",
    "\n",
    "# transform to torch tensor\n",
    "tensor_x_data = torch.Tensor(x_data)\n",
    "tensor_y_data = torch.Tensor(y_data)\n",
    "# create your datset\n",
    "dataset = TensorDataset(tensor_x_data ,tensor_y_data)\n",
    "# the batch size can be changed to a lrger value when you have more data\n",
    "batch_size = 1\n",
    "# create your dataloader\n",
    "dataloader = DataLoader(dataset , batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor_x_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-6348417c2a08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_x_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtensor_y_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tensor_x_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(tensor_x_data.shape,tensor_y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available () else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork , self).__init__ ()\n",
    "        self.flatten = nn.Flatten ()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            # the size of input should be the number of features (20 MFCC) times\n",
    "            # length of sequence (313)\n",
    "            nn.Linear(20*313 , 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512 , 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512 , 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256 , 4)\n",
    "        )\n",
    "    def forward(self , x):\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        \n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "model = NeuralNetwork().to(device)\n",
    "# to train a model , we need a loss function and an optimizer .\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters (), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader , model , loss_fn , optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train ()\n",
    "    for batch , (X, y) in enumerate(dataloader):\n",
    "        \n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred , y.type(torch.LongTensor))\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad ()\n",
    "        loss.backward ()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss , current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "def test(dataloader , model , loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss , correct = 0, 0\n",
    "    with torch.no_grad ():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred , y.type(torch.LongTensor)).item()\n",
    "            \n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 50\n",
    "for t in range(number_of_epochs):\n",
    "    #print(model)\n",
    "    print(loss_fn)\n",
    "    #print(optimizer)\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(dataloader , model , loss_fn , optimizer)\n",
    "    #test(dataloader , model , loss_fn)\n",
    "    \n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset , DataLoader\n",
    "import torch\n",
    "data_dir= \"C:/Users/matte/Desktop/IA/Data/SONG_TEST/\"\n",
    "\n",
    "# Read file info file to get the list of audio files and their labels\n",
    "file_list=[]\n",
    "label_list=[]\n",
    "\n",
    "with open(data_dir+\"info.txt\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        # The first column contains the file name\n",
    "        file_list.append(row[0])\n",
    "        # The last column contains the lable (language)\n",
    "        label_list.append(row[0][0])\n",
    "\n",
    "\n",
    "        \n",
    "# create a dictionary for labels\n",
    "lang_dic={'0':0,'1':1,'2':2,'3':3,}\n",
    "# create a list of extracted feature (MFCC) for files\n",
    "x_data_test=[]\n",
    "for audio_file in file_list:\n",
    "    \n",
    "    print(audio_file)\n",
    "    file_feature = feature_extractor(data_dir+audio_file)\n",
    "    #add extracted feature to dataset\n",
    "    x_data_test.append(file_feature)\n",
    "    \n",
    "# create a list of labels for files\n",
    "y_data_test=[]\n",
    "for lang_label in label_list:\n",
    "    #convert the label to a value in {0,1,2,3} as the class label\n",
    "    #print(lang_dic[lang_label])\n",
    "    y_data_test.append(lang_dic[lang_label])\n",
    "    \n",
    "    \n",
    "# shuffle two lists\n",
    "temp_list = list(zip(x_data_test , y_data_test))\n",
    "random.shuffle(temp_list)\n",
    "x_data_test , y_data_test = zip(*temp_list)\n",
    "x_data_test=np.array(x_data_test)\n",
    "y_data_test=np.array(y_data_test)\n",
    "# transform to torch tensor\n",
    "tensor_x_data_test = torch.Tensor(x_data_test)\n",
    "tensor_y_data_test = torch.Tensor(y_data_test)\n",
    "# create your datset\n",
    "dataset_test = TensorDataset(tensor_x_data_test ,tensor_y_data_test)\n",
    "# the batch size can be changed to a lrger value when you have more data\n",
    "batch_size = 1\n",
    "# create your dataloader\n",
    "dataloader_test = DataLoader(dataset_test , batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test(dataloader_test , model , loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
