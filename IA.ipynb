{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The duration of 0_0000.wav in seconds: 10.0\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "# sr should be set to your recording sample rate (16k)\n",
    "x,freq = librosa.load(\"C:/Users/matte/Desktop/IA/HIP_HOP_MUSIC/0_0000.wav\",sr=16000)\n",
    "# The load function will return a time series value (x) and\n",
    "# the input sample rate (freq) which is 16000\n",
    "print(\"The duration of 0_0000.wav in seconds:\",len(x)/freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The duration of 0_0000.wav in seconds: 10.0\n"
     ]
    }
   ],
   "source": [
    "x=x[:160000]\n",
    "print(\"The duration of 0_0000.wav in seconds:\",len(x)/freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 313)\n"
     ]
    }
   ],
   "source": [
    "# This function will return n_mfcc number of MFCC per\n",
    "# a window of time in audio time series\n",
    "x_mfcc=librosa.feature.mfcc(x,sr=freq , n_mfcc=40)\n",
    "print(x_mfcc.shape)\n",
    "\n",
    "# x_mfcc is an array with 40 values for a window of time\n",
    "# The len(x_mfcc) is a proportion of wav file duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matte\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/matte/Desktop/IA/Data/HIP_HOP_MUSIC/0_0263.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'r+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid file: {0!r}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m         _error_check(_snd.sf_error(file_ptr),\n\u001b[0m\u001b[0;32m   1184\u001b[0m                      \"Error opening {0!r}: \".format(self.name))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[1;34m(err, prefix)\u001b[0m\n\u001b[0;32m   1356\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1357\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error opening 'C:/Users/matte/Desktop/IA/Data/HIP_HOP_MUSIC/0_0263.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3567d9b52e14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0mfile_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[1;31m#add extracted feature to dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mx_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-3567d9b52e14>\u001b[0m in \u001b[0;36mfeature_extractor\u001b[1;34m(audio_file_dir)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_file_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#load the audio files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_file_dir\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;31m#extract 20 MFCCs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mmfcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreq\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mn_mfcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPurePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\audioread\\__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\audioread\\rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \"\"\"\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/matte/Desktop/IA/Data/HIP_HOP_MUSIC/0_0263.wav'"
     ]
    }
   ],
   "source": [
    "#NE PAS EXECUTER CE CODE, MAIS CELUI D'APRES (fin vous pouvez mais ça sert à rien)\n",
    "#\n",
    "#\n",
    "#On garde ce code car c'est une autre façon de faire\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "def feature_extractor(audio_file_dir):\n",
    "    #load the audio files\n",
    "    x,freq = librosa.load(audio_file_dir ,sr=16000)\n",
    "    #extract 20 MFCCs\n",
    "    mfcc=librosa.feature.mfcc(x,sr=freq ,n_mfcc=20)\n",
    "    # calculate the mean and variance of each MFFC\n",
    "    mean_mfccs=np.mean(mfcc ,axis=1)\n",
    "    var_mfccs=np.var(mfcc ,axis=1)\n",
    "    #return mean and variance as the audio file feature\n",
    "    return list(mean_mfccs)+list(var_mfccs)\n",
    "\n",
    "#set data_dir to the directory of your data files\n",
    "data_dir= \"C:/Users/matte/Desktop/IA/Data/HIP_HOP_MUSIC/\"\n",
    "\n",
    "# Read file info file to get the list of audio files and their labels\n",
    "file_list=[]\n",
    "label_list=[]\n",
    "\n",
    "\n",
    "with open(data_dir+\"info.txt\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        # The first column contains the file name\n",
    "        file_list.append(row[0])\n",
    "        # The last column contains the lable (language)\n",
    "        label_list.append(row[0][0])\n",
    "\n",
    "#set data_dir to the directory of your data files\n",
    "data_dir= \"C:/Users/matte/Desktop/IA/Data/CLASSIC_MUSIC/\"\n",
    "\n",
    "with open(data_dir+\"info.txt\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        # The first column contains the file name\n",
    "        file_list.append(row[0])\n",
    "        # The last column contains the lable (language)\n",
    "        label_list.append(row[0][0])\n",
    "\n",
    "        \n",
    "        \n",
    "data_dir= \"C:/Users/matte/Desktop/IA/Data/HIP_HOP_MUSIC/\"\n",
    "# create a dictionary for labels\n",
    "lang_dic={'0':0,'1':1,'2':2,'3':3,}\n",
    "# create a list of extracted feature (MFCC) for files\n",
    "x_data=[]\n",
    "for audio_file in file_list:\n",
    "    \n",
    "    if audio_file[0]=='1':\n",
    "        data_dir= \"C:/Users/matte/Desktop/IA/Data/CLASSIC_MUSIC/\"\n",
    "        \n",
    "    \n",
    "    file_feature = feature_extractor(data_dir+audio_file)\n",
    "    #add extracted feature to dataset\n",
    "    x_data.append(file_feature)\n",
    "    \n",
    "# create a list of labels for files\n",
    "y_data=[]\n",
    "for lang_label in label_list:\n",
    "    #convert the label to a value in {0,1,2,3} as the class label\n",
    "    print(lang_dic[lang_label])\n",
    "    y_data.append(lang_dic[lang_label])\n",
    "    \n",
    "    \n",
    "# shuffle two lists\n",
    "temp_list = list(zip(x_data , y_data))\n",
    "random.shuffle(temp_list)\n",
    "x_data , y_data = zip(*temp_list)\n",
    "# create Random Forest model from sklearn to classify languages of audio files\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "x_test = x_data[:len(x_data) // 8]\n",
    "y_test = y_data[:len(y_data) // 8]\n",
    "\n",
    "x_train = x_data[len(x_data) // 8:]\n",
    "y_train = y_data[len(y_data) // 8:]\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# the resulted accuracy is on a small set which is same for train and test\n",
    "print(\"Accuracy\",clf.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(audio_file_dir):\n",
    "#load the audio files\n",
    "    x,freq = librosa.load(audio_file_dir ,sr=16000)\n",
    "# trim the first 5 seconds (Sequence Truncation )\n",
    "    x_10sec=x[:160000]\n",
    "# extract 20 MFCCs\n",
    "    mfccs_10sec=librosa.feature.mfcc(x_10sec ,sr=freq ,n_mfcc=20)\n",
    "# return mfcc of the first 5 sec as the audio file feature\n",
    "    return mfccs_10sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_0000.wav\n",
      "0_0001.wav\n",
      "0_0002.wav\n",
      "0_0003.wav\n",
      "0_0004.wav\n",
      "0_0005.wav\n",
      "0_0006.wav\n",
      "0_0007.wav\n",
      "0_0008.wav\n",
      "0_0009.wav\n",
      "0_0010.wav\n",
      "0_0011.wav\n",
      "0_0012.wav\n",
      "0_0013.wav\n",
      "0_0014.wav\n",
      "0_0015.wav\n",
      "0_0016.wav\n",
      "0_0017.wav\n",
      "0_0018.wav\n",
      "0_0019.wav\n",
      "0_0020.wav\n",
      "0_0021.wav\n",
      "0_0022.wav\n",
      "0_0023.wav\n",
      "0_0024.wav\n",
      "0_0025.wav\n",
      "0_0026.wav\n",
      "0_0027.wav\n",
      "0_0028.wav\n",
      "0_0029.wav\n",
      "0_0030.wav\n",
      "0_0031.wav\n",
      "0_0032.wav\n",
      "0_0033.wav\n",
      "0_0034.wav\n",
      "0_0035.wav\n",
      "0_0036.wav\n",
      "0_0037.wav\n",
      "0_0038.wav\n",
      "0_0039.wav\n",
      "1_0000.wav\n",
      "1_0001.wav\n",
      "1_0002.wav\n",
      "1_0003.wav\n",
      "1_0004.wav\n",
      "1_0005.wav\n",
      "1_0006.wav\n",
      "1_0007.wav\n",
      "1_0008.wav\n",
      "1_0009.wav\n",
      "1_0010.wav\n",
      "1_0011.wav\n",
      "1_0012.wav\n",
      "1_0013.wav\n",
      "1_0014.wav\n",
      "1_0015.wav\n",
      "1_0016.wav\n",
      "1_0017.wav\n",
      "1_0018.wav\n",
      "1_0019.wav\n",
      "1_0020.wav\n",
      "1_0021.wav\n",
      "1_0023.wav\n",
      "1_0024.wav\n",
      "1_0025.wav\n",
      "1_0026.wav\n",
      "1_0027.wav\n",
      "1_0028.wav\n",
      "1_0029.wav\n",
      "1_0030.wav\n",
      "1_0031.wav\n",
      "1_0032.wav\n",
      "1_0033.wav\n",
      "1_0034.wav\n",
      "1_0035.wav\n",
      "1_0036.wav\n",
      "1_0037.wav\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset , DataLoader\n",
    "import torch\n",
    "data_dir= \"C:/Users/matte/Desktop/IA/Data/HIP_HOP_MUSIC/\"\n",
    "\n",
    "# Read file info file to get the list of audio files and their labels\n",
    "file_list=[]\n",
    "label_list=[]\n",
    "\n",
    "with open(data_dir+\"info.txt\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        # The first column contains the file name\n",
    "        file_list.append(row[0])\n",
    "        # The last column contains the lable (language)\n",
    "        label_list.append(row[0][0])\n",
    "\n",
    "#set data_dir to the directory of your data files\n",
    "data_dir= \"C:/Users/matte/Desktop/IA/Data/CLASSIC_MUSIC/\"\n",
    "\n",
    "with open(data_dir+\"info.txt\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        # The first column contains the file name\n",
    "        file_list.append(row[0])\n",
    "        # The last column contains the lable (language)\n",
    "        label_list.append(row[0][0])\n",
    "\n",
    "        \n",
    "        \n",
    "data_dir= \"C:/Users/matte/Desktop/IA/Data/HIP_HOP_MUSIC/\"\n",
    "# create a dictionary for labels\n",
    "lang_dic={'0':0,'1':1,'2':2,'3':3,}\n",
    "# create a list of extracted feature (MFCC) for files\n",
    "x_data=[]\n",
    "for audio_file in file_list:\n",
    "    if audio_file[0]=='1':\n",
    "        data_dir= \"C:/Users/matte/Desktop/IA/Data/CLASSIC_MUSIC/\"\n",
    "        \n",
    "    print(audio_file)\n",
    "    file_feature = feature_extractor(data_dir+audio_file)\n",
    "    #add extracted feature to dataset\n",
    "    x_data.append(file_feature)\n",
    "    \n",
    "# create a list of labels for files\n",
    "y_data=[]\n",
    "for lang_label in label_list:\n",
    "    #convert the label to a value in {0,1,2,3} as the class label\n",
    "    #print(lang_dic[lang_label])\n",
    "    y_data.append(lang_dic[lang_label])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# shuffle two lists\n",
    "temp_list = list(zip(x_data , y_data))\n",
    "random.shuffle(temp_list)\n",
    "x_data , y_data = zip(*temp_list)\n",
    "\n",
    "\n",
    "# transform to torch tensor\n",
    "tensor_x_data = torch.Tensor(x_data)\n",
    "tensor_y_data = torch.Tensor(y_data)\n",
    "# create your datset\n",
    "dataset = TensorDataset(tensor_x_data ,tensor_y_data)\n",
    "# the batch size can be changed to a lrger value when you have more data\n",
    "batch_size = 1\n",
    "# create your dataloader\n",
    "dataloader = DataLoader(dataset , batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([77, 20, 313]) torch.Size([77])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_x_data.shape,tensor_y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\matte\\anaconda3\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\matte\\anaconda3\\lib\\site-packages (from torch) (4.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available () else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork , self).__init__ ()\n",
    "        self.flatten = nn.Flatten ()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            # the size of input should be the number of features (20 MFCC) times\n",
    "            # length of sequence (313)\n",
    "            nn.Linear(20*313 , 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512 , 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512 , 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256 , 4)\n",
    "        )\n",
    "    def forward(self , x):\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        \n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "model = NeuralNetwork().to(device)\n",
    "# to train a model , we need a loss function and an optimizer .\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters (), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader , model , loss_fn , optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train ()\n",
    "    for batch , (X, y) in enumerate(dataloader):\n",
    "        \n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred , y.type(torch.LongTensor))\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad ()\n",
    "        loss.backward ()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss , current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "def test(dataloader , model , loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss , correct = 0, 0\n",
    "    with torch.no_grad ():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred , y.type(torch.LongTensor)).item()\n",
    "            \n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss()\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.965721 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.032632 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.568853 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.200179 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.057233 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.102552 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.020522 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.605962 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.796845 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.213984 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.032134 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.016362 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.015888 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.013045 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.010636 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.008956 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.007682 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.006793 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.005946 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.005263 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.004710 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.004264 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.003842 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.003556 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.003274 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.003017 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.002813 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.002619 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.002454 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.002310 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.002176 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.002060 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.001950 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.001863 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.001762 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.001681 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.001613 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.001539 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.001474 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.001416 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.001352 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.001307 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.001253 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.001206 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.001164 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.001123 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.001088 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.001050 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.001020 [    0/   77]\n",
      "CrossEntropyLoss()\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.000987 [    0/   77]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "number_of_epochs = 50\n",
    "for t in range(number_of_epochs):\n",
    "    #print(model)\n",
    "    print(loss_fn)\n",
    "    #print(optimizer)\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(dataloader , model , loss_fn , optimizer)\n",
    "    #test(dataloader , model , loss_fn)\n",
    "    \n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_0000.wav\n",
      "0_0001.wav\n",
      "0_0002.wav\n",
      "0_0003.wav\n",
      "0_0004.wav\n",
      "0_0005.wav\n",
      "0_0006.wav\n",
      "0_0007.wav\n",
      "0_0008.wav\n",
      "0_0009.wav\n",
      "0_0010.wav\n",
      "1_0000.wav\n",
      "1_0001.wav\n",
      "1_0002.wav\n",
      "1_0003.wav\n",
      "1_0004.wav\n",
      "1_0005.wav\n",
      "1_0006.wav\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset , DataLoader\n",
    "import torch\n",
    "data_dir= \"C:/Users/matte/Desktop/IA/Data/SONG_TEST/\"\n",
    "\n",
    "# Read file info file to get the list of audio files and their labels\n",
    "file_list=[]\n",
    "label_list=[]\n",
    "\n",
    "with open(data_dir+\"info.txt\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        # The first column contains the file name\n",
    "        file_list.append(row[0])\n",
    "        # The last column contains the lable (language)\n",
    "        label_list.append(row[0][0])\n",
    "\n",
    "\n",
    "        \n",
    "# create a dictionary for labels\n",
    "lang_dic={'0':0,'1':1,'2':2,'3':3,}\n",
    "# create a list of extracted feature (MFCC) for files\n",
    "x_data_test=[]\n",
    "for audio_file in file_list:\n",
    "    \n",
    "    print(audio_file)\n",
    "    file_feature = feature_extractor(data_dir+audio_file)\n",
    "    #add extracted feature to dataset\n",
    "    x_data_test.append(file_feature)\n",
    "    \n",
    "# create a list of labels for files\n",
    "y_data_test=[]\n",
    "for lang_label in label_list:\n",
    "    #convert the label to a value in {0,1,2,3} as the class label\n",
    "    #print(lang_dic[lang_label])\n",
    "    y_data_test.append(lang_dic[lang_label])\n",
    "    \n",
    "    \n",
    "# shuffle two lists\n",
    "temp_list = list(zip(x_data_test , y_data_test))\n",
    "random.shuffle(temp_list)\n",
    "x_data_test , y_data_test = zip(*temp_list)\n",
    "x_data_test=np.array(x_data_test)\n",
    "y_data_test=np.array(y_data_test)\n",
    "# transform to torch tensor\n",
    "tensor_x_data_test = torch.Tensor(x_data_test)\n",
    "tensor_y_data_test = torch.Tensor(y_data_test)\n",
    "# create your datset\n",
    "dataset_test = TensorDataset(tensor_x_data_test ,tensor_y_data_test)\n",
    "# the batch size can be changed to a lrger value when you have more data\n",
    "batch_size = 1\n",
    "# create your dataloader\n",
    "dataloader_test = DataLoader(dataset_test , batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.179116 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(dataloader_test , model , loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
