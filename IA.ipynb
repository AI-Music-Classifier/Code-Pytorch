{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The duration of 0_0000.wav in seconds: 10.0\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "# sr should be set to your recording sample rate (16k)\n",
    "x,freq = librosa.load(\"C:/Users/matte/Desktop/IA/HIP_HOP_MUSIC/0_0000.wav\",sr=16000)\n",
    "# The load function will return a time series value (x) and\n",
    "# the input sample rate (freq) which is 16000\n",
    "print(\"The duration of 0_0000.wav in seconds:\",len(x)/freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The duration of 0_0000.wav in seconds: 10.0\n"
     ]
    }
   ],
   "source": [
    "x=x[:160000]\n",
    "print(\"The duration of 0_0000.wav in seconds:\",len(x)/freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 313)\n"
     ]
    }
   ],
   "source": [
    "# This function will return n_mfcc number of MFCC per\n",
    "# a window of time in audio time series\n",
    "x_mfcc=librosa.feature.mfcc(x,sr=freq , n_mfcc=40)\n",
    "print(x_mfcc.shape)\n",
    "\n",
    "# x_mfcc is an array with 40 values for a window of time\n",
    "# The len(x_mfcc) is a proportion of wav file duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_0000.wav\n",
      "0_0001.wav\n",
      "0_0002.wav\n",
      "0_0003.wav\n",
      "0_0004.wav\n",
      "0_0005.wav\n",
      "0_0006.wav\n",
      "0_0007.wav\n",
      "0_0008.wav\n",
      "0_0009.wav\n",
      "0_0010.wav\n",
      "0_0011.wav\n",
      "0_0012.wav\n",
      "0_0013.wav\n",
      "0_0014.wav\n",
      "0_0015.wav\n",
      "0_0016.wav\n",
      "0_0017.wav\n",
      "0_0018.wav\n",
      "0_0019.wav\n",
      "0_0020.wav\n",
      "0_0021.wav\n",
      "0_0022.wav\n",
      "0_0023.wav\n",
      "0_0024.wav\n",
      "0_0025.wav\n",
      "0_0026.wav\n",
      "0_0027.wav\n",
      "0_0028.wav\n",
      "0_0029.wav\n",
      "0_0030.wav\n",
      "0_0031.wav\n",
      "0_0032.wav\n",
      "0_0033.wav\n",
      "0_0034.wav\n",
      "0_0035.wav\n",
      "0_0036.wav\n",
      "0_0037.wav\n",
      "0_0038.wav\n",
      "0_0039.wav\n",
      "0_0040.wav\n",
      "0_0041.wav\n",
      "0_0042.wav\n",
      "0_0043.wav\n",
      "0_0044.wav\n",
      "0_0045.wav\n",
      "0_0046.wav\n",
      "0_0047.wav\n",
      "0_0048.wav\n",
      "0_0049.wav\n",
      "0_0050.wav\n",
      "0_0051.wav\n",
      "0_0052.wav\n",
      "0_0053.wav\n",
      "0_0054.wav\n",
      "0_0055.wav\n",
      "0_0056.wav\n",
      "0_0057.wav\n",
      "0_0058.wav\n",
      "0_0059.wav\n",
      "0_0060.wav\n",
      "0_0061.wav\n",
      "0_0062.wav\n",
      "0_0063.wav\n",
      "0_0064.wav\n",
      "0_0065.wav\n",
      "0_0066.wav\n",
      "0_0067.wav\n",
      "0_0068.wav\n",
      "0_0069.wav\n",
      "0_0070.wav\n",
      "0_0071.wav\n",
      "0_0072.wav\n",
      "0_0073.wav\n",
      "0_0074.wav\n",
      "0_0075.wav\n",
      "0_0076.wav\n",
      "0_0077.wav\n",
      "0_0078.wav\n",
      "0_0079.wav\n",
      "0_0080.wav\n",
      "0_0081.wav\n",
      "0_0082.wav\n",
      "0_0083.wav\n",
      "0_0084.wav\n",
      "0_0085.wav\n",
      "0_0086.wav\n",
      "0_0087.wav\n",
      "0_0088.wav\n",
      "0_0089.wav\n",
      "0_0090.wav\n",
      "0_0091.wav\n",
      "0_0092.wav\n",
      "0_0093.wav\n",
      "0_0094.wav\n",
      "0_0095.wav\n",
      "0_0096.wav\n",
      "0_0097.wav\n",
      "0_0098.wav\n",
      "0_0099.wav\n",
      "0_0100.wav\n",
      "0_0101.wav\n",
      "0_0102.wav\n",
      "0_0103.wav\n",
      "0_0104.wav\n",
      "0_0105.wav\n",
      "0_0106.wav\n",
      "0_0107.wav\n",
      "0_0108.wav\n",
      "0_0109.wav\n",
      "0_0110.wav\n",
      "0_0111.wav\n",
      "0_0112.wav\n",
      "0_0113.wav\n",
      "0_0115.wav\n",
      "0_0116.wav\n",
      "0_0117.wav\n",
      "0_0118.wav\n",
      "0_0119.wav\n",
      "0_0120.wav\n",
      "0_0121.wav\n",
      "0_0122.wav\n",
      "0_0123.wav\n",
      "0_0124.wav\n",
      "0_0125.wav\n",
      "0_0126.wav\n",
      "0_0127.wav\n",
      "0_0128.wav\n",
      "0_0129.wav\n",
      "0_0130.wav\n",
      "0_0131.wav\n",
      "0_0132.wav\n",
      "0_0133.wav\n",
      "0_0134.wav\n",
      "0_0135.wav\n",
      "0_0139.wav\n",
      "0_0140.wav\n",
      "0_0141.wav\n",
      "0_0142.wav\n",
      "0_0143.wav\n",
      "0_0144.wav\n",
      "0_0145.wav\n",
      "0_0146.wav\n",
      "0_0147.wav\n",
      "0_0149.wav\n",
      "0_0150.wav\n",
      "0_0151.wav\n",
      "0_0152.wav\n",
      "0_0153.wav\n",
      "0_0154.wav\n",
      "0_0155.wav\n",
      "0_0156.wav\n",
      "0_0157.wav\n",
      "0_0158.wav\n",
      "0_0159.wav\n",
      "0_0160.wav\n",
      "0_0161.wav\n",
      "0_0162.wav\n",
      "0_0163.wav\n",
      "0_0164.wav\n",
      "0_0165.wav\n",
      "0_0166.wav\n",
      "0_0167.wav\n",
      "0_0168.wav\n",
      "0_0169.wav\n",
      "0_0170.wav\n",
      "0_0171.wav\n",
      "0_0172.wav\n",
      "0_0173.wav\n",
      "0_0174.wav\n",
      "0_0175.wav\n",
      "0_0176.wav\n",
      "0_0177.wav\n",
      "0_0178.wav\n",
      "0_0179.wav\n",
      "0_0180.wav\n",
      "0_0181.wav\n",
      "0_0182.wav\n",
      "0_0183.wav\n",
      "0_0184.wav\n",
      "0_0185.wav\n",
      "0_0186.wav\n",
      "0_0187.wav\n",
      "0_0188.wav\n",
      "0_0189.wav\n",
      "0_0190.wav\n",
      "0_0191.wav\n",
      "0_0192.wav\n",
      "0_0193.wav\n",
      "0_0194.wav\n",
      "0_0195.wav\n",
      "0_0196.wav\n",
      "0_0197.wav\n",
      "0_0198.wav\n",
      "0_0199.wav\n",
      "0_0200.wav\n",
      "0_0201.wav\n",
      "0_0202.wav\n",
      "0_0203.wav\n",
      "0_0204.wav\n",
      "0_0205.wav\n",
      "0_0206.wav\n",
      "0_0207.wav\n",
      "0_0208.wav\n",
      "0_0209.wav\n",
      "0_0210.wav\n",
      "0_0211.wav\n",
      "0_0212.wav\n",
      "0_0213.wav\n",
      "0_0214.wav\n",
      "0_0215.wav\n",
      "0_0216.wav\n",
      "0_0217.wav\n",
      "0_0218.wav\n",
      "0_0219.wav\n",
      "0_0220.wav\n",
      "0_0221.wav\n",
      "0_0222.wav\n",
      "0_0223.wav\n",
      "0_0224.wav\n",
      "0_0225.wav\n",
      "0_0226.wav\n",
      "0_0227.wav\n",
      "0_0228.wav\n",
      "0_0229.wav\n",
      "0_0230.wav\n",
      "0_0231.wav\n",
      "0_0232.wav\n",
      "0_0233.wav\n",
      "0_0234.wav\n",
      "0_0235.wav\n",
      "0_0236.wav\n",
      "0_0237.wav\n",
      "0_0238.wav\n",
      "0_0239.wav\n",
      "0_0240.wav\n",
      "0_0241.wav\n",
      "0_0242.wav\n",
      "0_0243.wav\n",
      "0_0244.wav\n",
      "0_0245.wav\n",
      "0_0246.wav\n",
      "0_0247.wav\n",
      "0_0248.wav\n",
      "0_0249.wav\n",
      "0_0250.wav\n",
      "0_0251.wav\n",
      "0_0252.wav\n",
      "0_0253.wav\n",
      "0_0254.wav\n",
      "0_0255.wav\n",
      "0_0256.wav\n",
      "0_0257.wav\n",
      "0_0258.wav\n",
      "0_0259.wav\n",
      "0_0260.wav\n",
      "0_0261.wav\n",
      "0_0262.wav\n",
      "0_0263.wav\n",
      "0_0264.wav\n",
      "0_0265.wav\n",
      "0_0266.wav\n",
      "0_0267.wav\n",
      "0_0268.wav\n",
      "0_0269.wav\n",
      "0_0270.wav\n",
      "0_0271.wav\n",
      "0_0272.wav\n",
      "0_0273.wav\n",
      "0_0274.wav\n",
      "0_0275.wav\n",
      "0_0276.wav\n",
      "0_0277.wav\n",
      "0_0278.wav\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "def feature_extractor(audio_file_dir):\n",
    "    #load the audio files\n",
    "    x,freq = librosa.load(audio_file_dir ,sr=16000)\n",
    "    #extract 20 MFCCs\n",
    "    mfcc=librosa.feature.mfcc(x,sr=freq ,n_mfcc=20)\n",
    "    # calculate the mean and variance of each MFFC\n",
    "    mean_mfccs=np.mean(mfcc ,axis=1)\n",
    "    var_mfccs=np.var(mfcc ,axis=1)\n",
    "    #return mean and variance as the audio file feature\n",
    "    return list(mean_mfccs)+list(var_mfccs)\n",
    "\n",
    "#set data_dir to the directory of your data files\n",
    "data_dir= \"C:/Users/matte/Desktop/IA/HIP_HOP_MUSIC/\"\n",
    "\n",
    "# Read file info file to get the list of audio files and their labels\n",
    "file_list=[]\n",
    "label_list=[]\n",
    "with open(data_dir+\"info.txt\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        # The first column contains the file name\n",
    "        file_list.append(row[0])\n",
    "        # The last column contains the lable (language)\n",
    "        label_list.append(row[0][0])\n",
    "    \n",
    "# create a dictionary for labels\n",
    "lang_dic={'0':0,'1':1,'2':2,'3':3,}\n",
    "# create a list of extracted feature (MFCC) for files\n",
    "x_data=[]\n",
    "for audio_file in file_list:\n",
    "    print(audio_file)\n",
    "    file_feature = feature_extractor(data_dir+audio_file)\n",
    "    #add extracted feature to dataset\n",
    "    x_data.append(file_feature)\n",
    "    \n",
    "# create a list of labels for files\n",
    "y_data=[]\n",
    "for lang_label in label_list:\n",
    "    #convert the label to a value in {0,1,2,3} as the class label\n",
    "    print(lang_dic[lang_label])\n",
    "    y_data.append(lang_dic[lang_label])\n",
    "    \n",
    "    \n",
    "# shuffle two lists\n",
    "temp_list = list(zip(x_data , y_data))\n",
    "random.shuffle(temp_list)\n",
    "x_data , y_data = zip(*temp_list)\n",
    "# create Random Forest model from sklearn to classify languages of audio files\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "x_test = x_data[:len(x_data) // 8]\n",
    "y_test = y_data[:len(y_data) // 8]\n",
    "\n",
    "x_train = x_data[len(x_data) // 8:]\n",
    "y_train = y_data[len(y_data) // 8:]\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# the resulted accuracy is on a small set which is same for train and test\n",
    "print(\"Accuracy\",clf.score(x_test, y_test))\n",
    "\n",
    "# JUSQU'ICI C'EST OKKKKKKK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(audio_file_dir):\n",
    "#load the audio files\n",
    "    x,freq = librosa.load(audio_file_dir ,sr=16000)\n",
    "# trim the first 5 seconds (Sequence Truncation )\n",
    "    x_10sec=x[:160000]\n",
    "# extract 20 MFCCs\n",
    "    mfccs_10sec=librosa.feature.mfcc(x_10sec ,sr=freq ,n_mfcc=20)\n",
    "# return mfcc of the first 5 sec as the audio file feature\n",
    "    return mfccs_10sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-b60b84851a80>:38: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  tensor_x_data = torch.Tensor(x_data)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset , DataLoader\n",
    "import torch\n",
    "data_dir= \"\"\n",
    "\n",
    "# Read file info file to get the list of audio files and their labels\n",
    "file_list=[]\n",
    "label_list=[]\n",
    "with open(data_dir+\"info.txt\", 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        # The first column contains the file name\n",
    "        file_list.append(row[0])\n",
    "        # The last column contains the lable (language)\n",
    "        label_list.append(row[-1])\n",
    "    \n",
    "# create a dictionary for labels\n",
    "lang_dic={'EN':0,'FR':1,'AR':2,'JP':3,}\n",
    "# create a list of extracted feature (MFCC) for files\n",
    "x_data=[]\n",
    "for audio_file in file_list:\n",
    "    file_feature = feature_extractor(data_dir+audio_file)\n",
    "    #add extracted feature to dataset\n",
    "    x_data.append(file_feature)\n",
    "    \n",
    "# create a list of labels for files\n",
    "y_data=[]\n",
    "for lang_label in label_list:\n",
    "    #convert the label to a value in {0,1,2,3} as the class label\n",
    "    #print(lang_dic[lang_label])\n",
    "    y_data.append(lang_dic[lang_label])\n",
    "    \n",
    "    \n",
    "# shuffle two lists\n",
    "temp_list = list(zip(x_data , y_data))\n",
    "random.shuffle(temp_list)\n",
    "x_data , y_data = zip(*temp_list)\n",
    "# transform to torch tensor\n",
    "tensor_x_data = torch.Tensor(x_data)\n",
    "tensor_y_data = torch.Tensor(y_data)\n",
    "# create your datset\n",
    "dataset = TensorDataset(tensor_x_data ,tensor_y_data)\n",
    "# the batch size can be changed to a lrger value when you have more data\n",
    "batch_size = 1\n",
    "# create your dataloader\n",
    "dataloader = DataLoader(dataset , batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20, 157]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_x_data.shape,tensor_y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\matte\\anaconda3\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\matte\\anaconda3\\lib\\site-packages (from torch) (3.7.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available () else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork , self).__init__ ()\n",
    "        self.flatten = nn.Flatten ()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            # the size of input should be the number of features (20 MFCC) times\n",
    "            # length of sequence (157)\n",
    "            nn.Linear(20*157 , 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512 , 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512 , 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256 , 4)\n",
    "        )\n",
    "    def forward(self , x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "model = NeuralNetwork ().to(device)\n",
    "# to train a model , we need a loss function and an optimizer .\n",
    "loss_fn = nn.CrossEntropyLoss ()\n",
    "optimizer = torch.optim.SGD(model.parameters (), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader , model , loss_fn , optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train ()\n",
    "    for batch , (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred , y.type(torch.LongTensor))\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad ()\n",
    "        loss.backward ()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss , current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "def test(dataloader , model , loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss , correct = 0, 0\n",
    "    with torch.no_grad ():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred , y.type(torch.LongTensor)).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.114457 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 25.0%, Avg loss: 1.839349 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.351344 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 25.0%, Avg loss: 1.736820 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.330320 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 25.0%, Avg loss: 2.125407 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.221009 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 25.0%, Avg loss: 1.546297 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.539356 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 25.0%, Avg loss: 1.581583 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.538783 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 25.0%, Avg loss: 1.629614 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.294597 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 25.0%, Avg loss: 2.084637 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.168778 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 25.0%, Avg loss: 1.707771 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.132348 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 28.1%, Avg loss: 1.730000 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.072861 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 28.1%, Avg loss: 1.955704 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.047925 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 40.6%, Avg loss: 2.162543 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.007169 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.481949 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.066685 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.479407 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.008723 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 1.117543 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.086356 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 1.742459 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.004374 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.967182 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.029016 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.819731 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.244700 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 0.862511 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.071856 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.706980 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.124008 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 1.124982 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.005025 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 2.084796 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.009008 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.717390 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.046621 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.573175 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.315634 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.596731 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.018867 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.564207 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.022079 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 0.647488 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.014592 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.913393 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.003821 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 28.1%, Avg loss: 12.431470 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.000004 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.550116 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.237728 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.416035 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.084199 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.405784 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.023623 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.333960 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.009363 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.069582 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.163233 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 2.423851 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.001448 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.473068 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.045269 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 0.968897 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.018691 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.902878 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.003796 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 3.047929 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.000034 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 1.651853 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.001750 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.487970 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.079801 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.238492 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.024318 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.463736 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.236946 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 0.803421 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.537220 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.529813 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.139853 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 1.644490 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.003629 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.185585 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.044883 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.845069 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.021478 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.350904 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.069755 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.625514 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.034686 [    0/   32]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.562939 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "number_of_epochs = 50\n",
    "for t in range(number_of_epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(dataloader , model , loss_fn , optimizer)\n",
    "    test(dataloader , model , loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 0, 2, 1, 0, 2, 1, 1, 2, 2, 3, 2, 2, 0, 1, 3, 1, 3, 3, 2, 0, 0, 1, 0, 0, 3, 1, 1, 0, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
